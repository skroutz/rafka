#!/usr/bin/env ruby
ENV["BUNDLE_GEMFILE"] ||= File.expand_path("Gemfile", File.dirname(__FILE__))

require "bundler/setup"
Bundler.setup(:default)
require "securerandom"
require "minitest/autorun"
require "rafka"
require_relative "test_helper"

host_port = (ENV["RAFKA"] || "localhost:6381").split(":")
host, port = host_port[0], Integer(host_port[1])

CLIENT_DEFAULTS = { host: host, port: port, redis: { reconnect_attempts: 5 } }
FLUSH_TIMEOUT = 5000
CONSUME_RETRIES = 3
CONSUME_TIMEOUT = 5

class TestRafka < Minitest::Test
  def setup
    @prod = Rafka::Producer.new(CLIENT_DEFAULTS)
  end

  def test_consume_many
    with_new_topic(consumer: true) do |topic, cons|
      start_consumer!(cons)

      3.times { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      replies = []
      3.times do |i|
        msg = consume_with_retry(cons)
        assert_rafka_msg msg
        replies << msg.value
      end

      assert_equal ["0", "1", "2"], replies.sort
    end
  end

  def test_produce_with_key
    with_new_topic(consumer: true) do |topic, cons|
      start_consumer!(cons)

      100.times { |i| @prod.produce(topic, i, key: 'foo') }
      assert_flushed @prod

      partitions = []
      100.times do |i|
        msg = consume_with_retry(cons)
        assert_rafka_msg msg
        partitions << msg.partition
      end

      assert_equal 1, partitions.uniq.size
    end
  end

  def test_many_consumers_same_topic
    with_new_topic do |topic|
      gid = rand_id
      cons1 = Rafka::Consumer.new(CLIENT_DEFAULTS.merge(topic: topic, group: gid, id: "cons1"))
      cons2 = Rafka::Consumer.new(CLIENT_DEFAULTS.merge(topic: topic, group: gid, id: "cons2"))
      start_consumer!(cons1)
      start_consumer!(cons2)

      msgs = ["a", "b"]
      msgs.each { |msg| @prod.produce(topic, msg) }
      assert_flushed @prod

      replies = []
      tries = 0

      while replies.size < 2 && tries < 10
        tries += 1

        msg = cons1.consume(1) || cons2.consume(1)
        next if !msg

        replies << msg.value
        replies.uniq!
      end

      assert_equal msgs.sort, replies.sort
    end
  end

  def test_consumer_group_rebalance
    with_new_topic do |topic|
      gid = rand_id
      cons1 = Rafka::Consumer.new(CLIENT_DEFAULTS.merge(topic: topic, group: gid, id: "cons1"))
      cons2 = Rafka::Consumer.new(CLIENT_DEFAULTS.merge(topic: topic, group: gid, id: "cons2"))
      msg1 = "hi"
      msg2 = "hello"

      start_consumer!(cons1)
      produce_and_flush!(@prod, topic, msg1)
      assert_rafka_msg_equal msg1, consume_with_retry(cons1)

      # commit offsets and shutdown so that cons2 gets all the partitions
      cons1.close
      start_consumer!(cons2)

      produce_and_flush!(@prod, topic, msg2)

      incoming = consume_with_retry(cons2)
      assert_rafka_msg incoming

      if incoming.value != msg2
        # it means cons2 was assigned the partition before cons1's offsets
        # were commited
        assert_rafka_msg_equal msg1, incoming
        assert_rafka_msg_equal msg2, consume_with_retry(cons2)
      else
        assert_rafka_msg_equal msg2, incoming
      end
    end
  end

  def test_many_consumers_different_topics
    with_new_topic(consumer: true) do |topic1, cons1|
      with_new_topic(consumer: true) do |topic2, cons2|
        start_consumer!(cons1)
        start_consumer!(cons2)

        @prod.produce(topic1, "I'm Mr. Meeseeks")
        @prod.produce(topic2, "Look at me")
        assert_flushed @prod

        assert_rafka_msg_equal "I'm Mr. Meeseeks", consume_with_retry(cons1)
        assert_rafka_msg_equal "Look at me", consume_with_retry(cons2)
      end
    end
  end

  def test_produce_wrong_topic
    assert_raises Rafka::ProduceError do
      # TODO(agis): first produce won't do it. This is a Rafka issue.
      @prod.produce("idontexist", "foo")
      @prod.flush
      @prod.produce("idontexist", "foo")
    end
  end

  def test_cgroup_reconnect_single_partition
    with_new_topic(partitions: 1) do |topic|
      produce_and_flush!(@prod, topic, "foo")
      group_a = "a_group"
      cons = new_consumer(topic: topic, group: group_a)
      assert_rafka_msg_equal "foo", consume_with_retry(cons)
      cons.close

      produce_and_flush!(@prod, topic, "bar")

      assert_rafka_msg_equal "bar", consume_with_retry(
        new_consumer(topic: topic, group: group_a))

      cons = new_consumer(topic: topic, group: "another_group")
      assert_rafka_msg_equal "foo", consume_with_retry(cons)
      assert_rafka_msg_equal "bar", consume_with_retry(cons)
    end
  end

  # This tests a real-world scenario where a client app restarts (eg. during
  # deployment), thus stopping and restarting its consumers.
  #
  # The flow is the following:
  #
  #   1. Consumers of a group (we call it cgroup) are consuming from topic Y
  #   2. Values are produced to topic Y
  #   3. cgroup consumes the produced values
  #   4. cgroup is restarted (ie. app is deployed)
  #   5. More values are produced to topic Y
  #   6. cgroup continues consuming from the last position, ie. it doesn't
  #      reconsume values from step (2) but only from (5)
  def test_cgroup_reconnect_many_partitions
    partitions = 4
    input_size = 20
    reconsumes_tolerated = partitions + 2
    flunk "input_size must be even, given: #{input_size}" if input_size.odd?

    with_new_topic(partitions: partitions) do |topic|
      group = "cgroupA"
      input = (1..input_size)
      input_a, input_b = input.each_slice(input_size/2).to_a
      output = Hash.new(0)

      # produce some input and consume it
      cgroup = Array.new(2) { new_consumer(topic: topic, group: group) }
      cgroup.each { |c| start_consumer!(c) }
      input_a.each { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      while output.size < input_a.size
        cgroup.each do |c|
          msg = c.consume(1)
          output[msg.value.to_i] += 1 if msg
        end
      end

      assert_equal input_a.to_a, output.keys.sort

      # restart cgroup to simulate client app deployment
      cgroup.each { |c| c.close }

      sleep 2 # sleep more than the auto.commit interval so that a commit will kick in

      # produce some more input and assert cgroup continues where it left
      # position (ie. does not re-consume input_a)
      cgroup = Array.new(2) { new_consumer(topic: topic, group: group) }
      cgroup.each { |c| start_consumer!(c) }
      input_b.each { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      while output.size < input_size
        cgroup.each do |c|
          msg = c.consume(1)
          output[msg.value.to_i] += 1 if msg
        end
      end

      assert_equal input.to_a, output.keys.sort

      actual_reconsumes = output.values.inject(:+) - input_size
      assert actual_reconsumes <= reconsumes_tolerated,
        "Expected reconsumes to be <= #{reconsumes_tolerated}, " \
        "was #{actual_reconsumes}"
    end
  end

  def test_consumer_id_reclaim
    group, id = rand_id, rand_id
    cons = new_consumer(topic: "a-topic", group: group, id: id)
    cons.consume(1)
    cons.close

    cons = new_consumer(topic: "a-topic", group: group, id: id)
    cons.consume(1)
  end

  def test_consumer_id_uniqueness
    group, id = rand_id, rand_id
    cons1 = new_consumer(topic: "a-topic", group: group, id: id)
    cons1.consume(1)

    cons2 = new_consumer(topic: "a-topic", group: group, id: id)
    assert_raises Rafka::ConsumeError do
      cons2.consume(1)
    end
  end

  def test_stats
    stats = @prod.redis.hgetall("stats")
    assert stats.size > 0
    stats.keys.each { |k| assert_kind_of String, k }
    stats.values.each { |v| assert_kind_of Integer, Integer(v) }
  end

  def test_stats_reset
    @prod.redis.del("stats")
    @prod.produce("foo", "asemas")
    sleep 0.5
    assert_equal @prod.redis.hgetall("stats")["producer.delivery.errors"], "1"

    @prod.redis.del("stats")
    assert @prod.redis.hgetall("stats")["producer.delivery.errors"], "0"
  end

  def test_consumer_manual_commit
    n = 50
    abort "n (#{n}) must be an even number" if n.odd?
    gid = rand_id

    with_new_topic(consumer: true, partitions: 2) do |topic|
      cons = Rafka::Consumer.new(CLIENT_DEFAULTS.merge(
        topic: topic, group: gid, id: "a", auto_commit: false))
      start_consumer!(cons)

      n.times { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      msg = nil

      # do a plain consume of all messages, without committing offsets
      n.times do
        msg = consume_with_retry(cons)
        assert_rafka_msg(msg)
        assert Integer(msg.value) < n
      end

      # restart consumer; we should start without any initial offsets since
      # we didn't commit
      cons.close
      msg = consume_with_retry(cons)
      assert_equal 0, msg.offset

      # restart and consume again; this time commit offsets
      cons.close
      msgs = []
      n.times do
        msg = consume_with_retry(cons)
        assert_rafka_msg(msg)
        msgs << msg
      end
      res = cons.commit(*msgs)

      # close causes rafka to issue a commit offsets request
      cons.close

      # restart and consume some newly-produced messages; we expect to
      # start with the previous offsets since we did commit. There's still
      # a small window until the offsets are actually committed to Kafka and
      # if we hit it, we expect the following assertions to fail.
      n.times { |i| @prod.produce(topic, n+i) }
      assert_flushed @prod

      n.times do
        msg = consume_with_retry(cons)
        assert_rafka_msg(msg)
        assert Integer(msg.value) >= n
      end

      cons.close
    end
  end

  def test_consumer_batch
    with_new_topic(consumer: true) do |topic, cons|
      50.times { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      msgs = cons.consume_batch(timeout: 0.3, batch_size: 30, batching_max_sec: 5)
      assert_equal 30, msgs.size

      msgs = cons.consume_batch(timeout: 0.3, batch_size: 9999, batching_max_sec: 2)
      assert_equal 20, msgs.size

      50.times { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      msgs = cons.consume_batch(timeout: 0.3, batch_size: 30, batching_max_sec: 0)
      assert_equal 30, msgs.size

      msgs = cons.consume_batch(timeout: 0.3, batch_size: 0, batching_max_sec: 2)
      assert_equal 20, msgs.size
    end
  end

  def test_consumer_batch_commit
    with_new_topic(consumer: true, partitions: 1) do |topic, cons|
      50.times { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      msgs = cons.consume_batch(timeout: 0.3, batch_size: 10)
      msgs.map! { |m| Integer(m.value) }.sort!
      assert_equal 9, msgs.last

      # close and re-consume; we should start from the previous point
      cons.close
      msgs = cons.consume_batch(timeout: 0.3, batch_size: 5)
      msgs.map! { |m| Integer(m.value) }.sort!
      assert_equal 14, msgs.last


      assert_raises RuntimeError do
        # close and re-consume with a block; we should start from the previous
        # point
        cons.close
        cons.consume_batch(timeout: 0.3, batch_size: 5) do |msgs|
          results = msgs.map { |m| Integer(m.value) }.sort
          assert_equal 19, results.last

          # raise an error to avoid committing the offsets
          raise "foo"
        end
      end

      # close and re-consume; we should get again the same messages since
      # the previous consume didn't commit offsets
      cons.close
      msgs = cons.consume_batch(timeout: 0.3, batch_size: 5)
      msgs.map! { |m| Integer(m.value) }.sort!
      assert_equal 19, msgs.last
    end
  end

  def test_consume_with_block
    with_new_topic(consumer: true, partitions: 1) do |topic, cons|
      10.times { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      msg = nil

      assert_rafka_msg(cons.consume)
      cons.consume do |msg|
        assert_equal 1, Integer(msg.value)
      end

      # close and restart; we should continue from where we left
      cons.close
      cons.consume do |msg|
        assert_equal 2, Integer(msg.value)
      end

      # consume with a block that raises an error; offsets shouldn't be
      # committed
      cons.close
      assert_raises RuntimeError do
        cons.consume do |msg|
          assert_equal 3, Integer(msg.value)

          # raise an error to avoid committing the offsets
          raise "foo"
        end
      end

      # close and re-consume; we should start again from the already consumed
      # messages b/c offsets weren't committed
      cons.close
      assert_equal 3, Integer(cons.consume.value)
    end
  end

  def test_consumer_librdkafka_config
    invalid_configs = [
      { "foo": "bar" },
      { "session.timeout.ms": true },
    ]

    invalid_configs.each do |cfg|
      assert_raises Rafka::ConsumeError do
        start_consumer!(new_consumer(topic: "foo", librdkafka: cfg))
      end
    end

    valid_configs = [
      {},
      {"session.timeout.ms": 12345, "log.connection.close": false},
    ]

    valid_configs.each do |cfg|
      start_consumer!(new_consumer(topic: "foo", librdkafka: cfg))
    end

    with_new_topic do |topic|
      produce_and_flush!(@prod, topic, "foo")

      cons = new_consumer(topic: topic, librdkafka: { "auto.offset.reset" => "latest" })
      assert_nil cons.consume(5)

      produce_and_flush!(@prod, topic, "bar")
      assert_rafka_msg_equal "bar", cons.consume(5)
    end
  end
end

puts "\nRunning on #{host_port.join(":")} " \
     "(rafka-rb #{Rafka::VERSION}, redis-rb #{Redis::VERSION} " \
     "CONSUME_RETRIES=#{CONSUME_RETRIES}, CONSUME_TIMEOUT=#{CONSUME_TIMEOUT})..."

retries = 0
rafka_up = false

while retries < 4 && !rafka_up
  retries += 1

  begin
    rafka_up = Rafka::Producer.new(CLIENT_DEFAULTS).ping == "PONG"
  rescue => Redis::CannotConnectError
    rafka_up = false
    sleep 1
  end
end

abort "Could not PING Rafka server. Is it up?" if !rafka_up

$topics = []

MiniTest.after_run do
  puts "Deleting (#{$topics.count}) test topics..."
  $topics.each { |t| delete_kafka_topic!(t) }
end
