#!/usr/bin/env ruby
ENV["BUNDLE_GEMFILE"] ||= File.expand_path("Gemfile", File.dirname(__FILE__))

require "bundler/setup"
Bundler.setup(:default)
require "securerandom"
require "minitest/autorun"
require "rafka"
require_relative "test_helper"

host_port = (ENV["RAFKA"] || "localhost:6380").split(":")
host, port = host_port[0], Integer(host_port[1])

CLIENT_DEFAULTS = { host: host, port: port, redis: { reconnect_attempts: 5 } }
FLUSH_TIMEOUT = 5000
CONSUME_RETRIES = 3
CONSUME_TIMEOUT = 1

class TestRafka < Minitest::Test
  def setup
    @prod = Rafka::Producer.new(CLIENT_DEFAULTS)
  end

  def test_consume_many
    with_new_topic(consumer: true) do |topic, cons|
      start_consumer!(cons)

      3.times { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      replies = []
      3.times do |i|
        msg = consume_with_retry(cons)
        assert_rafka_msg msg
        replies << msg.value
      end

      assert_equal ["0", "1", "2"], replies.sort
    end
  end

  def test_produce_with_key
    with_new_topic(consumer: true) do |topic, cons|
      start_consumer!(cons)

      100.times { |i| @prod.produce(topic, i, key: 'foo') }
      assert_flushed @prod

      partitions = []
      100.times do |i|
        msg = consume_with_retry(cons)
        assert_rafka_msg msg
        partitions << msg.partition
      end

      assert_equal 1, partitions.uniq.size
    end
  end

  def test_many_consumers_same_topic
    with_new_topic do |topic|
      gid = rand_id
      cons1 = Rafka::Consumer.new(CLIENT_DEFAULTS.merge(topic: topic, group: gid, id: "cons1"))
      cons2 = Rafka::Consumer.new(CLIENT_DEFAULTS.merge(topic: topic, group: gid, id: "cons2"))
      start_consumer!(cons1)
      start_consumer!(cons2)

      msgs = ["a", "b"]
      msgs.each { |msg| @prod.produce(topic, msg) }
      assert_flushed @prod

      replies = []
      tries = 0

      while replies.size < 2 && tries < 6
        tries += 1

        msg = consume_with_retry(cons1) || consume_with_retry(cons2)
        next if !msg

        replies << msg.value
        replies.uniq!
      end

      assert_equal msgs.sort, replies.sort
    end
  end

  def test_consumer_group_rebalance
    with_new_topic do |topic|
      gid = rand_id
      cons1 = Rafka::Consumer.new(CLIENT_DEFAULTS.merge(topic: topic, group: gid, id: "cons1"))
      cons2 = Rafka::Consumer.new(CLIENT_DEFAULTS.merge(topic: topic, group: gid, id: "cons2"))
      msg1 = "hi"
      msg2 = "hello"

      start_consumer!(cons1)
      produce_and_flush!(@prod, topic, msg1)
      assert_rafka_msg_equal msg1, consume_with_retry(cons1)

      # commit offsets and shutdown so that cons2 gets all the partitions
      cons1.close
      start_consumer!(cons2)

      produce_and_flush!(@prod, topic, msg2)

      incoming = consume_with_retry(cons2)
      assert_rafka_msg incoming

      if incoming.value != msg2
        # it means cons2 was assigned the partition before cons1's offsets
        # were commited
        assert_rafka_msg_equal msg1, incoming
        assert_rafka_msg_equal msg2, consume_with_retry(cons2)
      else
        assert_rafka_msg_equal msg2, incoming
      end
    end
  end

  def test_many_consumers_different_topics
    with_new_topic(consumer: true) do |topic1, cons1|
      with_new_topic(consumer: true) do |topic2, cons2|
        start_consumer!(cons1)
        start_consumer!(cons2)

        @prod.produce(topic1, "I'm Mr. Meeseeks")
        @prod.produce(topic2, "Look at me")
        assert_flushed @prod

        assert_rafka_msg_equal "I'm Mr. Meeseeks", consume_with_retry(cons1)
        assert_rafka_msg_equal "Look at me", consume_with_retry(cons2)
      end
    end
  end

  def test_produce_wrong_topic
    assert_raises Rafka::ProduceError do
      # TODO(agis): first produce won't do it. This is a Rafka issue.
      @prod.produce("idontexist", "foo")
      @prod.flush
      @prod.produce("idontexist", "foo")
    end
  end

  def test_cgroup_reconnect_single_partition
    with_new_topic(partitions: 1) do |topic|
      produce_and_flush!(@prod, topic, "foo")
      group_a = "a_group"
      cons = new_consumer(topic, group_a)
      assert_rafka_msg_equal "foo", consume_with_retry(cons)
      cons.close

      produce_and_flush!(@prod, topic, "bar")

      assert_rafka_msg_equal "bar", consume_with_retry(new_consumer(topic, group_a))

      cons = new_consumer(topic, "another_group")
      assert_rafka_msg_equal "foo", consume_with_retry(cons)
      assert_rafka_msg_equal "bar", consume_with_retry(cons)
    end
  end

  # This tests a real-world scenario where a client app restarts (eg. during
  # deployment), thus stopping and restarting its consumers.
  #
  # The flow is the following:
  #
  #   1. Consumers of a group (we call it cgroup) are consuming from topic Y
  #   2. Values are produced to topic Y
  #   3. cgroup consumes the produced values
  #   4. cgroup is restarted (ie. app is deployed)
  #   5. More values are produced to topic Y
  #   6. cgroup continues consuming from the last position, ie. it doesn't
  #      reconsume values from step (2) but only from (5)
  def test_cgroup_reconnect_many_partitions
    partitions = 4
    input_size = 20
    reconsumes_tolerated = partitions + 2
    flunk "input_size must be even, given: #{input_size}" if input_size.odd?

    with_new_topic(partitions: partitions) do |topic|
      group = "cgroupA"
      input = (1..input_size)
      input_a, input_b = input.each_slice(input_size/2).to_a
      output = Hash.new(0)

      # produce some input and consume it
      cgroup = Array.new(2) { new_consumer(topic, group) }
      cgroup.each { |c| start_consumer!(c) }
      input_a.each { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      while output.size < input_a.size
        cgroup.each do |c|
          msg = consume_with_retry(c, timeout: 1, retries: 1)
          output[msg.value.to_i] += 1 if msg
        end
      end

      assert_equal input_a.to_a, output.keys.sort

      # restart cgroup to simulate client app deployment
      cgroup.each { |c| c.close }

      # produce some more input and assert cgroup continues where it left
      # position (ie. does not re-consume input_a)
      cgroup = Array.new(2) { new_consumer(topic, group) }
      cgroup.each { |c| start_consumer!(c) }
      input_b.each { |i| @prod.produce(topic, i) }
      assert_flushed @prod

      while output.size < input_size
        cgroup.each do |c|
          msg = consume_with_retry(c, timeout: 1, retries: 1)
          output[msg.value.to_i] += 1 if msg
        end
      end

      assert_equal input.to_a, output.keys.sort

      actual_reconsumes = output.values.inject(:+) - input_size
      assert actual_reconsumes <= reconsumes_tolerated,
        "Expected reconsumes to be <= #{reconsumes_tolerated}, " \
        "was #{actual_reconsumes}"
    end
  end

  def test_consumer_id_reclaim
    group, id = rand_id, rand_id
    cons = new_consumer("a-topic", group, id)
    cons.consume(1)
    cons.close

    cons = new_consumer("a-topic", group, id)
    cons.consume(1)
  end

  def test_consumer_id_uniqueness
    group, id = rand_id, rand_id
    cons1 = new_consumer("a-topic", group, id)
    cons1.consume(1)

    cons2 = new_consumer("a-topic", group, id)
    assert_raises Rafka::ConsumeError do
      cons2.consume(1)
    end
  end

  def test_stats
    stats = @prod.redis.hgetall("stats")
    assert stats.size > 0
    stats.keys.each { |k| assert_kind_of String, k }
    stats.values.each { |v| assert_kind_of Integer, Integer(v) }
  end

  def test_stats_reset
    @prod.redis.del("stats")
    @prod.produce("foo", "asemas")
    sleep 0.5
    assert_equal @prod.redis.hgetall("stats")["producer.delivery.errors"], "1"

    @prod.redis.del("stats")
    assert @prod.redis.hgetall("stats")["producer.delivery.errors"], "0"
  end
end

puts "\nRunning on #{host_port.join(":")} " \
     "(rafka-rb #{Rafka::VERSION}, CONSUME_RETRIES=#{CONSUME_RETRIES}, " \
     "CONSUME_TIMEOUT=#{CONSUME_TIMEOUT})..."

if Rafka::Producer.new(CLIENT_DEFAULTS).ping != "PONG"
  abort "Could not PING Rafka server. Is it up?"
end

$topics = []

MiniTest.after_run do
  puts "Deleting (#{$topics.count}) test topics..."
  $topics.each { |t| delete_kafka_topic!(t) }
end
